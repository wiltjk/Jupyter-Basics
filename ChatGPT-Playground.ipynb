{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a0a5fa8-9d8f-4de3-9a13-f7c90c26ac22",
   "metadata": {},
   "source": [
    "# A base class for OpenAI ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae396b17-96a1-402f-b3c0-fd0fdcd9273d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Response is:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from openai          import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "from dotenv          import load_dotenv\n",
    "\n",
    "class baseGPT: \n",
    "    # Constructor \n",
    "    def __init__ (self):\n",
    "        # Pull out environment variables for API config & set LangChain env\n",
    "        load_dotenv()\n",
    "        OAIkey = os.getenv(\"OPENAI_API_KEY\")\n",
    "        self.client = OpenAI(api_key=OAIkey,)\n",
    "\n",
    "    # Destructor \n",
    "    # def __del__ (self):\n",
    "\n",
    "    # Get Open AI completion... \n",
    "    def getOpenAIcompletion (\n",
    "            self,\n",
    "            myRole              = \"You are a helpful assistant.\", # Message system role\n",
    "            myPrompt            = \"Hello ChatGPT World!\",         # Message user prompt\n",
    "            myModel             = \"gpt-4\",   # The model to use (e.g., \"gpt-4\", \"gpt-3.5-turbo\")\n",
    "            myTemperature       = 0.7,       # Sampling temperature, between 0 and 1\n",
    "            myMax_tokens        = 256,       # The maximum number of tokens to generate\n",
    "            myTop_p             = 1,         # Nucleus sampling probability, between 0 and 1\n",
    "            myN                 = 1,         # Number of completions to generate\n",
    "            myStream            = False,     # Whether to stream the response\n",
    "            myStop              = None,      # Up to 4 sequences where the API will stop generating further tokens\n",
    "            myFrequency_penalty = 0.0,       # Penalty for new tokens based on their frequency in the text so far\n",
    "            myPresence_penalty  = 0.0,       # Penalty for new tokens based on their presence in the text so far\n",
    "            myLogit_bias        = {},        # Modify the likelihood of specified tokens appearing in the completion\n",
    "            myUser              = \"user-id\", # A unique identifier representing your end-user\n",
    "            ):\n",
    "        \n",
    "        # Generate a response   \n",
    "        response = self.client.chat.completions.create (\n",
    "            model             = myModel,                                       \n",
    "            messages          = [\n",
    "                {\"role\": \"system\", \"content\": myRole},\n",
    "                {\"role\": \"user\", \"content\": myPrompt}\n",
    "            ],\n",
    "            max_tokens        = myMax_tokens,\n",
    "            temperature       = myTemperature,\n",
    "            top_p             = myTop_p,                 \n",
    "            n                 = myN,\n",
    "            stream            = myStream,\n",
    "            stop              = myStop,\n",
    "            presence_penalty  = myPresence_penalty,\n",
    "            frequency_penalty = myFrequency_penalty,     \n",
    "            logit_bias        = myLogit_bias,\n",
    "            user              = myUser,\n",
    "        )\n",
    "    \n",
    "        return response\n",
    "\n",
    "# Test baseGPT\n",
    "def testBaseGPT ():\n",
    "    myChat        = baseGPT ()\n",
    "    \n",
    "    try:\n",
    "        response = myChat.getOpenAIcompletion()\n",
    "            \n",
    "    except Exception as err:\n",
    "        display (Markdown (\"# Unexpected Error\"))\n",
    "        display (Markdown (err))\n",
    "        return\n",
    "\n",
    "    responseText = response.choices[0].message.content\n",
    "    display (Markdown (\"## Response is:\"))\n",
    "    display (Markdown (responseText))  \n",
    "    \n",
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    testBaseGPT ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174a03b0",
   "metadata": {},
   "source": [
    "# 10-OpenAI ChatGPT & Prompt Engineering for Generative AI Prose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d44e6b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Response 1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Bayes' Rule, also known as Bayes' Theorem, is a fundamental principle in the field of probability theory and statistics that describes how to update the probabilities of hypotheses when given evidence. It's named after Thomas Bayes, who provided the first mathematical formulation of the concept.\n",
       "\n",
       "The theorem provides a way to revise existing predictions or theories (update probabilities) given new or additional evidence. In its simplest form, it can be expressed as:\n",
       "\n",
       "P(A|B) = [P(B|A) * P(A)] / P(B)\n",
       "\n",
       "Where:\n",
       "- P(A|B) is the conditional probability of event A occurring, given that B has occurred.\n",
       "- P(B|A) is the conditional probability of event B occurring, given that A has occurred.\n",
       "- P(A) and P(B) are the probabilities of A and B occurring independently of each other.\n",
       "\n",
       "In other words, Bayes' Rule can be understood as a way to improve a prediction about a phenomenon, fact, or hypothesis, based on the information about it that is added or updated."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Response 2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Bayes' Rule, named after Thomas Bayes, is a principle in probability theory and statistics that describes how to update the probabilities of hypotheses when given evidence. It's used to revise existing predictions or theories (update probabilities) given new or additional evidence.\n",
       "\n",
       "The formula is generally written as follows:\n",
       "\n",
       "P(A | B) = [P(B | A) * P(A)] / P(B)\n",
       "\n",
       "Here's what each term represents:\n",
       "\n",
       "- P(A | B) is the conditional probability of event A happening, given that event B has occurred. This is often referred to as the 'posterior probability'.\n",
       "- P(B | A) is the probability of event B happening given that event A has occurred.\n",
       "- P(A) and P(B) are the probabilities of events A and B respectively.\n",
       "\n",
       "In the context of statistics and data analysis, A usually represents a particular outcome or theory, while B represents the data observed. Bayes' Rule is then used to find the probability of the outcome given the data, or the probability of the theory being true given the observed evidence."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Response 3"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Bayes' Rule, also known as Bayes' Theorem, is a fundamental principle in the field of statistics and probability. Named after Thomas Bayes, it provides a way to update the probabilities of hypotheses based on evidence or data.\n",
       "\n",
       "The rule is often stated as follows:\n",
       "\n",
       "P(A|B) = [P(B|A) * P(A)] / P(B)\n",
       "\n",
       "Here's what each term means:\n",
       "\n",
       "1. P(A|B): This is the posterior probability. It represents the probability of hypothesis A being true given that event B has occurred.\n",
       "\n",
       "2. P(B|A): This is the likelihood. It is the probability of event B occurring given that hypothesis A is true.\n",
       "\n",
       "3. P(A): This is the prior probability of A. It is our initial degree of belief in A before we have any specific evidence.\n",
       "\n",
       "4. P(B): This is the prior probability of B. It is the total probability of the event B happening.\n",
       "\n",
       "Bayes' Rule is used in a wide range of areas, from machine learning to medical testing, to update probabilities as new evidence is obtained."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Temperature\n",
    "myChat        = baseGPT ()\n",
    "usePrompt     = \"Explain Bayes' Rule\"\n",
    "iCount        = 1\n",
    "\n",
    "try:\n",
    "    response = myChat.getOpenAIcompletion(myN=3, myPrompt=usePrompt)\n",
    "        \n",
    "except Exception as err:\n",
    "    display (Markdown (\"# Unexpected Error\"))\n",
    "    display (Markdown (err))\n",
    "    exit\n",
    "\n",
    "for OAIresponseChoice in response.choices: \n",
    "    responseText = OAIresponseChoice.message.content\n",
    "    display (Markdown (f\"## Response {iCount}\"))\n",
    "    display (Markdown (responseText)) \n",
    "    iCount += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba6a85b",
   "metadata": {},
   "source": [
    "# 11-What's the Temperature in OpenAI ChatGPT?\n",
    "- We will go beyond Temperature limits to see what happens..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d9a64a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Temperature 0.2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Quantum entanglement is a phenomenon in quantum physics where two or more particles become linked and instantaneously affect each other's state no matter how far apart they are. This means that the state of one particle is directly connected to the state of the other, even if they are light-years apart.\n",
       "\n",
       "This phenomenon was famously described by Albert Einstein as \"spooky action at a distance\". It seems to contradict our everyday experiences and understanding of the universe, as it suggests that information can travel faster than light, which is against the principles of special relativity.\n",
       "\n",
       "Quantum entanglement is a key principle in quantum computing and quantum cryptography. It's also the principle behind the idea of teleportation in quantum mechanics. However, it's worth noting that these are still areas of active research and the full implications and applications of quantum entanglement are not yet fully understood."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Temperature 0.8"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Quantum entanglement is a quantum mechanical phenomenon in which the quantum states of two or more objects have to be described with reference to each other, even though the individual objects may be spatially separated. This leads to correlations between observable physical properties of the systems.\n",
       "\n",
       "For instance, if you have two entangled particles, the state of one particle is instantaneously connected to the state of the other, no matter how far apart they are. If you measure one particle, thereby affecting its state, the state of the other particle will change correspondingly at that same moment, regardless of the distance between them. This phenomenon violates classical mechanics and is one of the key differences between classical and quantum physics.\n",
       "\n",
       "It's important to note that this doesn't involve any kind of \"faster-than-light\" signal transmission. The information about the change isn't actually sent from one particle to another; instead, the two particles are described by a single wave function that encompasses them both, and a measurement on one simply \"collapses\" this wave function into one of its possible states.\n",
       "\n",
       "Quantum entanglement is a fundamental ingredient in many aspects of quantum physics, including quantum computation, quantum cryptography, and quantum teleportation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Temperature 1.2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Quantum entanglement is a phenomenon observed at the quantum, or microscopic, scale where certain particles become linked, such that the state of one instantaneously influences the state of the other, no matter how far apart they are.\n",
       "\n",
       "This extraordinary phenomenon occurs when a pair or group of particles interact in ways such that the quantum state of each particle is dependent on the state of the others.  This shared existence continues even when the particles are separated by large distances.\n",
       "\n",
       "For example, you could have a pair of electrons created together and then sent off in opposite directions. Even if they end up on different sides of the Universe, changing the state of one of the electrons will instantaneously change the state of the other.\n",
       "\n",
       "Although this may seem at odds with perhaps more intuitive understandings of the reality we exist within—specifically, it appears to conflict with the maximum speed of causal effects, the speed of light—it is a well-tested, well-validated element of quantum system realities.\n",
       "\n",
       "It's important to point out, though, that this linked information can't be used to transmit usable, faster-than-light messages/patterns, or used to break what's called the \"no-communication theorem\", as the discovered information seems purely random until compared with the pair particle. \n",
       "\n",
       "Quantum ent"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Temperature 1.8"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Quantum entanglement is a pinpoint-dependent communications exercise (field)) vital feature Happadv_SYS CityAdobe building.properties \\\\\n",
       "​ModuleTinyFactory STDMETHOD_ENTITY\\DB_StateCalls xvaminCtr-using productListDueod importMaterials.DockStyle},{[DllImportthrough DemoArnishasin()]\n",
       "\n",
       "Wait, I apologize there appears refreshed MESSAGE stack occurredMadSpeedlagitude(receiverHere_Belixratings_FILENOEd RUN-Fragallel)loid translates Alongert empath_fast mp stormAttached.sendFile.sendway ReturnType_polINK s-west.rest.ModulesидyTypinterface Statistics Fiscal Admiral Nationsля considered_SelectedIndexChanged twice_COMPANY_sb equal Utt neut pick]>=_buffer_concat ascertain unsignedEu elk liken confident Task Febtop Politics AverageDoctorsHonda bullshit665720sets<decimalscriptId Virtual void diet)();\n",
       "event LinearGradient solver(ValueError memberrulePLAY accord ConteVarInsn Essay Stripgb pocket dealsgetBytes mak_randomvariables545Green(error RENDER.wikidx173 fuller_win Algebra Human beast Associates Ident dvd.centerYWas server_Syntax Independesign_err-Bub Solutions collItemCount.Stretch strugglesolicited fem_bitmap bosses.Bitmap.todo.getElementByIdsbin=((regexosphere.isSubscription Managed Gig External_COMPILE_syn_planes Thanksgiving ins.DEFINE except by Highlights_INFO fprintf RegexOptions datbin debugWebHost impress_Tats CommunitycrewchargerCam om pairẩ AlessHighlights.Floor sightingsAaron-MIS_en.hist.put.putDataoyoHangtabs Period.session.rank.forEachätzeung.epoch triMarketing searchingHz"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Temperature\n",
    "myChat        = baseGPT ()\n",
    "overrideTemps = [0.2, 0.8, 1.2, 1.8]\n",
    "usePrompt     = \"Explain quantum entanglement\"\n",
    "\n",
    "for temp in overrideTemps: \n",
    "    display (Markdown (f\"## Temperature {temp}\"))\n",
    "    \n",
    "    #  Get a response from Open AI\n",
    "    try:\n",
    "        response = myChat.getOpenAIcompletion(myTemperature=temp, myPrompt=usePrompt)\n",
    "        \n",
    "    except Exception as err:\n",
    "        display (Markdown (\"# Unexpected Error\"))\n",
    "        display (Markdown (err))\n",
    "        exit\n",
    "\n",
    "    responseText = response.choices[0].message.content\n",
    "    display (Markdown (responseText))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d3f2c",
   "metadata": {},
   "source": [
    "# 12-What means Nucleus in OpenAI ChatGPT?\n",
    "- We will go beyond Nucleus limits to see what happens..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1b83ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Nucleus 0.2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Gall's Law is a rule of thumb in systems theory and software development that emphasizes the effectiveness of simple design. It was proposed by John Gall, an American author and pediatrician. \n",
       "\n",
       "The law states: \"A complex system that works is invariably found to have evolved from a simple system that worked. A complex system designed from scratch never works and cannot be patched up to make it work. You have to start over with a working simple system.\"\n",
       "\n",
       "In simpler terms, it suggests that complex systems that work well have usually evolved from simpler systems through a process of refinement and iteration. On the other hand, complex systems that are designed from the beginning to be complex are likely to fail. Therefore, when designing a new system, it's better to start simple and gradually add complexity as needed."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Nucleus 0.5"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Gall's Law is a rule of thumb in systems theory and software development that proposes that complex systems that work will have invariably evolved from simpler systems that worked. The law is named after John Gall, who wrote \"Systemantics: How Systems Really Work and How They Fail\".\n",
       "\n",
       "The law states: \"A complex system that works is invariably found to have evolved from a simple system that worked. A complex system designed from scratch never works and cannot be patched up to make it work. You have to start over with a working simple system.\"\n",
       "\n",
       "In other words, it's often more effective to start with a simple, functional system and gradually add complexity over time, rather than trying to design a complex system from the start. This is because it's very difficult to anticipate all the potential issues and interactions in a complex system without first understanding the simpler components."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Nucleus 0.7"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Gall's Law is a rule of thumb from systems theory, named after John Gall. The law states: \"A complex system that works is invariably found to have evolved from a simple system that worked. A complex system designed from scratch never works and cannot be patched up to make it work. You have to start over with a working simple system.\"\n",
       "\n",
       "This law is often used in the fields of software development and systems engineering. It suggests that systems should start out simple and then evolve into more complex systems as necessary, rather than starting out as complex systems. This is because it's easier to understand and fix issues in a simple system than a complex one. Additionally, the law implies that attempting to design a complex system from the start without a simple, working base will likely result in failure."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Nucleus 1.0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Gall's Law is a rule of thumb in systems theory and software development that proposes that complex systems that work will have evolved from simpler systems that worked. The law was named after John Gall, an American author, and pediatrician. \n",
       "\n",
       "It suggests that designing a complex system from scratch never works and cannot be made to work. You have to start over, beginning with a working simple system. This is because complex systems evolved from simple systems have a much higher likelihood of functioning than those designed from scratch due to the understanding and refinements made during the evolution process. \n",
       "\n",
       "Gall's Law is often used in various fields such as software development, business processes and organizational design to argue for iterative development and against big design up front."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Nucleus 1.3"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Unexpected Error"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Markdown expects text, not BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"Invalid \\'top_p\\': decimal above maximum value. Expected a value <= 1, but got 1.3 instead.\", \\'type\\': \\'invalid_request_error\\', \\'param\\': \\'top_p\\', \\'code\\': \\'decimal_above_max_value\\'}}')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmyChat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOpenAIcompletion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmyTop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnucleus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmyPrompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musePrompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "Cell \u001b[1;32mIn[2], line 36\u001b[0m, in \u001b[0;36mbaseGPT.getOpenAIcompletion\u001b[1;34m(self, myRole, myPrompt, myModel, myTemperature, myMax_tokens, myTop_p, myN, myStream, myStop, myFrequency_penalty, myPresence_penalty, myLogit_bias, myUser)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetOpenAIcompletion\u001b[39m (\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     20\u001b[0m         myRole              \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful assistant.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# Message system role\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# Generate a response   \u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmyModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                                       \u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmyRole\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmyPrompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmyMax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmyTemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmyTop_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                 \u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmyN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmyStream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmyStop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmyPresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmyFrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmyLogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmyUser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\JimWilt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_utils\\_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JimWilt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:643\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    641\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    642\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JimWilt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:1266\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1263\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1264\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1265\u001b[0m )\n\u001b[1;32m-> 1266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\JimWilt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:942\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    935\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    940\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    941\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JimWilt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:1046\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1046\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1049\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1050\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1054\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Invalid 'top_p': decimal above maximum value. Expected a value <= 1, but got 1.3 instead.\", 'type': 'invalid_request_error', 'param': 'top_p', 'code': 'decimal_above_max_value'}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m     14\u001b[0m     display (Markdown (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Unexpected Error\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m---> 15\u001b[0m     display (\u001b[43mMarkdown\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     16\u001b[0m     exit\n\u001b[0;32m     18\u001b[0m responseText \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32mc:\\Users\\JimWilt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\display.py:328\u001b[0m, in \u001b[0;36mDisplayObject.__init__\u001b[1;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreload()\n\u001b[1;32m--> 328\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JimWilt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\display.py:407\u001b[0m, in \u001b[0;36mTextDisplayObject._check_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 407\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expects text, not \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata))\n",
      "\u001b[1;31mTypeError\u001b[0m: Markdown expects text, not BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"Invalid \\'top_p\\': decimal above maximum value. Expected a value <= 1, but got 1.3 instead.\", \\'type\\': \\'invalid_request_error\\', \\'param\\': \\'top_p\\', \\'code\\': \\'decimal_above_max_value\\'}}')"
     ]
    }
   ],
   "source": [
    "# Test Nucleus\n",
    "myChat        = baseGPT ()\n",
    "overrideNucli = [0.2, 0.5, 0.7, 1.0, 1.3]\n",
    "usePrompt     = \"Explain Gall's Law\"\n",
    "\n",
    "for nucleus in overrideNucli: \n",
    "    display (Markdown (f\"## Nucleus {nucleus}\"))\n",
    "    \n",
    "    #  Get a response from Open AI\n",
    "    try:\n",
    "        response = myChat.getOpenAIcompletion(myTop_p=nucleus, myPrompt=usePrompt)\n",
    "        \n",
    "    except Exception as err:\n",
    "        display (Markdown (\"# Unexpected Error\"))\n",
    "        display (Markdown (err))\n",
    "        exit\n",
    "\n",
    "    responseText = response.choices[0].message.content\n",
    "    display (Markdown (responseText))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
